{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKPM6BBy4CsX"
   },
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2930,
     "status": "ok",
     "timestamp": 1749654334839,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "fdeBxJUxxHTc",
    "outputId": "3870e49b-cff3-4ef6-97a5-4dcfa43f1f81"
   },
   "outputs": [],
   "source": [
    "# Packages should be pre-installed in the environment\n",
    "# Dependencies: langgraph langchain-openai langchain-core langchain-google-genai pyyaml\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMSXkOax4EwC"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749654334849,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "J1MmjJpO357j"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Dict, List, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1749654334892,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "89oCQIAI5BUf"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from IPython.display import Image, display\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import re\n",
    "import tempfile\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6SG7LXHhMX8"
   },
   "source": [
    "# API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1749654334933,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "fFE7aN5BxUiC"
   },
   "outputs": [],
   "source": [
    "# Read API key from environment variable or file\n",
    "import os\n",
    "\n",
    "# First try to get API key from environment variable (for Cloud Run)\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "api_key_source = \"environment variable\"\n",
    "\n",
    "if api_key:\n",
    "    print(f\"‚úÖ API key loaded from environment variable\")\n",
    "else:\n",
    "    # Fallback to file-based approach for local development\n",
    "    # Get current working directory and script directory\n",
    "    current_dir = os.getcwd()\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else current_dir\n",
    "\n",
    "    # Try to find the api_key file in multiple possible locations\n",
    "    possible_paths = [\n",
    "        'api_key',  # Current directory\n",
    "        os.path.join(script_dir, 'api_key'),  # Same directory as script/notebook\n",
    "        os.path.join(current_dir, '..', 'api_key'),  # Parent directory (flask-app level)\n",
    "        os.path.join(script_dir, '..', 'api_key'),  # Parent of script directory\n",
    "        '/Users/leo/Documents/uni/master/25sose/NLP-social/WEBDEMO/flask-app/api_key',  # Flask app directory\n",
    "        '/Users/leo/Documents/uni/master/25sose/NLP-social/WEBDEMO/flask-app/backend/api_key'  # Backend directory\n",
    "    ]\n",
    "\n",
    "    api_key_source = None\n",
    "\n",
    "    for path in possible_paths:\n",
    "        try:\n",
    "            if os.path.exists(path):\n",
    "                with open(path, 'r') as f:\n",
    "                    api_key = f.read().strip()\n",
    "                api_key_source = path\n",
    "                print(f\"‚úÖ API key loaded from file: {path}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    if api_key is None:\n",
    "        print(\"‚ùå API key not found in environment variable or any file location.\")\n",
    "        print(f\"   Current working directory: {current_dir}\")\n",
    "        print(\"   For Cloud Run: Set GOOGLE_API_KEY environment variable\")\n",
    "        print(\"   For local development: Create an 'api_key' file with your Google API key\")\n",
    "        print(\"   Searched file paths:\")\n",
    "        for path in possible_paths:\n",
    "            abs_path = os.path.abspath(path)\n",
    "            exists = \"‚úì\" if os.path.exists(path) else \"‚úó\"\n",
    "            print(f\"   {exists} {path} -> {abs_path}\")\n",
    "        print(\"   Get your API key from: https://aistudio.google.com/app/apikey\")\n",
    "\n",
    "# Uncomment and use these if you prefer environment variables instead:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgiyYknF4IjC"
   },
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oet6ZqhWZuYo"
   },
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1749654334935,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "zem3UumH2OWa"
   },
   "outputs": [],
   "source": [
    "# # Initialize LLM\n",
    "# llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF5MKsCqYEw4"
   },
   "source": [
    "## Gemini\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/rate-limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749654334936,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "E4NNrDwQ3_no"
   },
   "outputs": [],
   "source": [
    "# # Initialize Gemini LLM (using free model)\n",
    "# llm = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-2.5-flash-preview-05-20\",  # Free model\n",
    "#     temperature=0.7,\n",
    "#     google_api_key=api_key\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1749654334937,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "KqgORfyLYGV6"
   },
   "outputs": [],
   "source": [
    "# Initialize Gemini LLM (using free model)\n",
    "if api_key:\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash-001\",  # Free model\n",
    "        temperature=0.3,\n",
    "        google_api_key=api_key\n",
    "    )\n",
    "    print(\"‚úÖ LLM initialized successfully\")\n",
    "else:\n",
    "    llm = None\n",
    "    print(\"‚ùå Cannot initialize LLM - no API key available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate Limiting Configuration\n",
    "\n",
    "Google Gemini API has these free tier limits:\n",
    "- **15 requests per minute** for gemini-2.0-flash\n",
    "- **1,500 requests per day** for free tier\n",
    "\n",
    "The notebook now includes automatic rate limiting and retry logic to handle quota exceeded errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API connection\n",
    "if llm is not None:\n",
    "    try:\n",
    "        print(\"üîç Testing API connection...\")\n",
    "        test_response = llm.invoke([{\"role\": \"user\", \"content\": \"Hello, can you respond with just 'API connection successful'?\"}])\n",
    "        print(f\"‚úÖ API test successful: {test_response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API connection failed: {e}\")\n",
    "        print(\"\\nPossible solutions:\")\n",
    "        print(\"1. Check your internet connection\")\n",
    "        print(\"2. Verify your API key is correct and active\")\n",
    "        print(\"3. Check if you have sufficient API quota\")\n",
    "        print(\"4. Try again in a few moments (rate limiting)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cannot test API - LLM not initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Connection Issues\n",
    "\n",
    "If you're experiencing connection errors, try these solutions:\n",
    "\n",
    "### Common Issues:\n",
    "1. **Invalid API Key**: Make sure your API key is correct and active\n",
    "2. **Network Issues**: Check your internet connection\n",
    "3. **Rate Limiting**: Google API has rate limits - wait a few minutes and try again\n",
    "4. **Quota Exceeded**: Check your API usage quota at [Google AI Studio](https://aistudio.google.com/)\n",
    "5. **Firewall/Proxy**: Corporate networks might block API calls\n",
    "\n",
    "### Quick Fixes:\n",
    "- Restart the notebook kernel and try again\n",
    "- Verify the `api_key` file contains only your API key (no extra spaces/characters)\n",
    "- Try running the API test cell above to isolate the issue\n",
    "- Check [Google AI Studio](https://aistudio.google.com/app/apikey) to verify your key is working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZago6r8Ao01"
   },
   "source": [
    "# Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749654334939,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "jAvQ2RXYAru8"
   },
   "outputs": [],
   "source": [
    "def load_case_from_file(file_path: str, scenario_number: int = None) -> str:\n",
    "    \"\"\"Load case details from text file\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the case file\n",
    "        scenario_number: If file contains multiple scenarios, specify which one (1, 2, 3, etc.)\n",
    "\n",
    "    Returns:\n",
    "        Case details as string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "\n",
    "        # Check if file contains multiple scenarios\n",
    "        if 'Scenario 1:' in content and 'Scenario 2:' in content:\n",
    "            scenarios = {}\n",
    "\n",
    "            # Split by scenario markers\n",
    "            parts = content.split('Scenario ')\n",
    "            for part in parts[1:]:  # Skip first empty part\n",
    "                if ':' in part:\n",
    "                    scenario_num = int(part.split(':')[0].strip())\n",
    "                    scenario_text = 'Scenario ' + part\n",
    "                    scenarios[scenario_num] = scenario_text.strip()\n",
    "\n",
    "            if scenario_number:\n",
    "                if scenario_number in scenarios:\n",
    "                    return scenarios[scenario_number]\n",
    "                else:\n",
    "                    available = list(scenarios.keys())\n",
    "                    raise ValueError(f\"Scenario {scenario_number} not found. Available scenarios: {available}\")\n",
    "            else:\n",
    "                # Return all scenarios combined\n",
    "                return content\n",
    "        else:\n",
    "            # Single case file\n",
    "            return content\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Case file {file_path} not found\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading case from {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749654334942,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "bh1yPaVQAx_L"
   },
   "outputs": [],
   "source": [
    "def select_scenario(scenarios: Dict[str, str]) -> str:\n",
    "    \"\"\"Allow user to select a scenario from loaded cases\"\"\"\n",
    "    if not scenarios:\n",
    "        return None\n",
    "\n",
    "    print(\"\\nAvailable scenarios:\")\n",
    "    scenario_list = list(scenarios.keys())\n",
    "\n",
    "    for i, scenario in enumerate(scenario_list, 1):\n",
    "        # Extract just the scenario title for display\n",
    "        title = scenario\n",
    "        if ':' in scenarios[scenario]:\n",
    "            first_line = scenarios[scenario].split('\\n')[0]\n",
    "            if 'Background:' in first_line:\n",
    "                title = f\"{scenario} - Murder case with eyewitness evidence\"\n",
    "        print(f\"{i}. {title}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(f\"\\nSelect scenario (1-{len(scenario_list)}) or 'back': \")\n",
    "            if choice.lower() == 'back':\n",
    "                return None\n",
    "\n",
    "            choice_num = int(choice)\n",
    "            if 1 <= choice_num <= len(scenario_list):\n",
    "                selected_scenario = scenario_list[choice_num - 1]\n",
    "                case_details = scenarios[selected_scenario]\n",
    "\n",
    "                # Display selected case\n",
    "                print(f\"\\n=== SELECTED CASE ===\")\n",
    "                print(case_details[:500] + \"...\" if len(case_details) > 500 else case_details)\n",
    "                print(\"=\" * 50)\n",
    "\n",
    "                confirm = input(\"\\nUse this scenario? (y/n): \")\n",
    "                if confirm.lower() in ['y', 'yes']:\n",
    "                    return case_details\n",
    "            else:\n",
    "                print(f\"Please enter a number between 1 and {len(scenario_list)}\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654334946,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "Xufn0Gpkmgk6"
   },
   "outputs": [],
   "source": [
    "def initialize_with_case(case_file_path: str, scenario_number: int = None):\n",
    "    \"\"\"Initialize the system with a case from file\"\"\"\n",
    "    global current_case, current_case_filename, current_scenario_number\n",
    "\n",
    "    try:\n",
    "        current_case = load_case_from_file(case_file_path, scenario_number)\n",
    "        current_case_filename = case_file_path  # Track the filename\n",
    "        current_scenario_number = scenario_number  # Track the scenario number\n",
    "\n",
    "        if scenario_number:\n",
    "            print(f\"‚úÖ Loaded Scenario {scenario_number} from {case_file_path}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Loaded case from {case_file_path}\")\n",
    "\n",
    "        # Show preview of the case\n",
    "        preview = current_case[:200] + \"...\" if len(current_case) > 200 else current_case\n",
    "        print(f\"Case Preview: {preview}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading case: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1749654334994,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "Gy8xGI8DFqge"
   },
   "outputs": [],
   "source": [
    "def list_scenarios_in_file(file_path: str):\n",
    "    \"\"\"List available scenarios in a case file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        scenarios = []\n",
    "        parts = content.split('Scenario ')\n",
    "        for part in parts[1:]:\n",
    "            if ':' in part:\n",
    "                scenario_num = int(part.split(':')[0].strip())\n",
    "                # Get first line after the colon as title\n",
    "                title_line = part.split('\\n')[0] if '\\n' in part else part[:50]\n",
    "                scenarios.append((scenario_num, title_line))\n",
    "\n",
    "        return scenarios\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRABptMi4Kjv"
   },
   "source": [
    "# Jury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1749654334997,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "-JAcLg5c2JNw"
   },
   "outputs": [],
   "source": [
    "class JuryState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    case_details: str\n",
    "    jury_backgrounds: Dict[str, str]\n",
    "    current_round: int\n",
    "    current_juror_index: int  # Track which juror is speaking within the round\n",
    "    total_rounds: int  # Total number of deliberation rounds\n",
    "    jury_order: List[str]  # Order of jury members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1749654334998,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "t2Ote-E82paj"
   },
   "outputs": [],
   "source": [
    "# Jury members and their backgrounds - FALLBACK\n",
    "JURY_MEMBERS = {\n",
    "    \"Alice\": \"Retired teacher, 30 years experience. Values fairness and second chances.\",\n",
    "    \"Bob\": \"Small business owner. Practical, fact-focused, believes in personal responsibility.\",\n",
    "    \"Carol\": \"Social worker with family court experience. Empathetic, considers circumstances.\",\n",
    "    \"David\": \"Engineer with technical background. Data-driven, prefers clear evidence.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oo7X33-5Jm1"
   },
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1749654335000,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "S3PC_aAy2sjW"
   },
   "outputs": [],
   "source": [
    "def load_backgrounds_from_files(file_paths: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"Load jury backgrounds from text files (legacy function for backward compatibility)\"\"\"\n",
    "    backgrounds = {}\n",
    "    jury_names = list(JURY_MEMBERS.keys())\n",
    "\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        if i >= len(jury_names):\n",
    "            break\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                backgrounds[jury_names[i]] = f.read().strip()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {file_path} not found, using default background\")\n",
    "            backgrounds[jury_names[i]] = JURY_MEMBERS[jury_names[i]]\n",
    "\n",
    "    # Fill remaining with defaults\n",
    "    for name in jury_names[len(file_paths):]:\n",
    "        backgrounds[name] = JURY_MEMBERS[name]\n",
    "\n",
    "    return backgrounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LftDGc0h5LAi"
   },
   "source": [
    "## YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1749654335001,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "KPfbioq8k-Bp"
   },
   "outputs": [],
   "source": [
    "def load_backgrounds_from_yaml(file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"Load jury backgrounds from YAML file supporting multiple structures\"\"\"\n",
    "    backgrounds = {}\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "\n",
    "        for jury_key, jury_data in data.items():\n",
    "            # Detect structure type by checking for key fields\n",
    "            if 'first_name' in jury_data and 'last_name' in jury_data:\n",
    "                # Detailed structure (like jurors.yaml)\n",
    "                background = _process_detailed_structure(jury_data)\n",
    "                full_name = f\"{jury_data.get('first_name', 'Unknown')} {jury_data.get('last_name', 'Unknown')}\"\n",
    "\n",
    "            elif 'backstory' in jury_data:\n",
    "                # Simplified structure (like agents.yaml, old_and_young.yaml)\n",
    "                background = _process_simplified_structure(jury_data)\n",
    "                full_name = _extract_name_from_backstory(jury_data.get('backstory', ''), jury_key)\n",
    "\n",
    "            else:\n",
    "                # Unknown structure - use available data\n",
    "                background = _process_unknown_structure(jury_data)\n",
    "                full_name = jury_key.replace('_', ' ').title()\n",
    "\n",
    "            backgrounds[full_name] = background\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"YAML file {file_path} not found, using default backgrounds\")\n",
    "        return JURY_MEMBERS.copy() if 'JURY_MEMBERS' in globals() else {}\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Error parsing YAML file {file_path}: {e}\")\n",
    "        return JURY_MEMBERS.copy() if 'JURY_MEMBERS' in globals() else {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading backgrounds from {file_path}: {e}\")\n",
    "        return JURY_MEMBERS.copy() if 'JURY_MEMBERS' in globals() else {}\n",
    "\n",
    "    return backgrounds\n",
    "\n",
    "\n",
    "def _process_detailed_structure(jury_data: Dict) -> str:\n",
    "    \"\"\"Process detailed structure with separate fields for personal information\"\"\"\n",
    "    biography = jury_data.get('biography', '')\n",
    "    age = jury_data.get('age', 'Unknown age')\n",
    "    education = jury_data.get('education', 'Unknown education')\n",
    "    occupation = jury_data.get('occupation', 'Unknown occupation')\n",
    "    income = jury_data.get('income', 'Unknown income')\n",
    "    state = jury_data.get('state', 'Unknown state')\n",
    "    religion = jury_data.get('religion', 'Unknown religion')\n",
    "    race = jury_data.get('race', 'Unknown race')\n",
    "    gender = jury_data.get('gender', 'Unknown gender')\n",
    "    goal = jury_data.get('goal', 'Serve justice fairly')\n",
    "    role = jury_data.get('role', 'Regular juror')\n",
    "\n",
    "    # Combine all information into a comprehensive background\n",
    "    background = f\"{biography}\\n\\n\"\n",
    "    background += f\"Personal Details: {age}, {gender}, {race}, {education}, {occupation} from {state}. \"\n",
    "    background += f\"Income: {income}. Religion: {religion}.\\n\"\n",
    "    background += f\"Role: {role}\\n\"\n",
    "    background += f\"Goal: {goal}\"\n",
    "\n",
    "    return background\n",
    "\n",
    "\n",
    "def _process_simplified_structure(jury_data: Dict) -> str:\n",
    "    \"\"\"Process simplified structure with backstory, role, and goal\"\"\"\n",
    "    backstory = jury_data.get('backstory', '').strip()\n",
    "    role = jury_data.get('role', '').strip()\n",
    "    goal = jury_data.get('goal', '').strip()\n",
    "\n",
    "    # Clean up multiline strings and remove template placeholders\n",
    "    backstory = re.sub(r'\\s+', ' ', backstory)\n",
    "    role = re.sub(r'\\s+', ' ', role)\n",
    "    goal = re.sub(r'\\s+', ' ', goal)\n",
    "\n",
    "    # Remove template placeholders like {topic} and {current_year}\n",
    "    backstory = re.sub(r'\\{[^}]+\\}', '[case topic]', backstory)\n",
    "    role = re.sub(r'\\{[^}]+\\}', '[case topic]', role)\n",
    "    goal = re.sub(r'\\{[^}]+\\}', '[case topic]', goal)\n",
    "\n",
    "    background = f\"{backstory}\\n\\n\"\n",
    "    if role and role != backstory:\n",
    "        background += f\"Role: {role}\\n\"\n",
    "    if goal and goal != backstory:\n",
    "        background += f\"Goal: {goal}\"\n",
    "\n",
    "    return background.strip()\n",
    "\n",
    "\n",
    "def _process_unknown_structure(jury_data: Dict) -> str:\n",
    "    \"\"\"Process unknown structure by using all available string data\"\"\"\n",
    "    background_parts = []\n",
    "\n",
    "    for key, value in jury_data.items():\n",
    "        if isinstance(value, str) and value.strip():\n",
    "            # Clean up multiline strings\n",
    "            clean_value = re.sub(r'\\s+', ' ', value.strip())\n",
    "            background_parts.append(f\"{key.replace('_', ' ').title()}: {clean_value}\")\n",
    "\n",
    "    return \"\\n\".join(background_parts) if background_parts else \"No background information available.\"\n",
    "\n",
    "\n",
    "def _extract_name_from_backstory(backstory: str, fallback_key: str) -> str:\n",
    "    \"\"\"Extract a name from the backstory text, with fallback to jury key\"\"\"\n",
    "    if not backstory:\n",
    "        return fallback_key.replace('_', ' ').title()\n",
    "\n",
    "    # Look for name patterns in the backstory\n",
    "    # Pattern 1: \"Name is a...\" or \"Name, a...\"\n",
    "    name_pattern1 = r'^([A-Z][a-z]+ [A-Z][a-z]+)\\s+(?:is|,)'\n",
    "    match1 = re.search(name_pattern1, backstory)\n",
    "    if match1:\n",
    "        return match1.group(1)\n",
    "\n",
    "    # Pattern 2: Just first sentence that might contain a name\n",
    "    name_pattern2 = r'^([A-Z][a-z]+ [A-Z][a-z]+)'\n",
    "    match2 = re.search(name_pattern2, backstory)\n",
    "    if match2:\n",
    "        return match2.group(1)\n",
    "\n",
    "    # Pattern 3: Look for any capitalized name in the first 50 characters\n",
    "    name_pattern3 = r'([A-Z][a-z]+ [A-Z][a-z]+)'\n",
    "    match3 = re.search(name_pattern3, backstory[:50])\n",
    "    if match3:\n",
    "        return match3.group(1)\n",
    "\n",
    "    # Fallback to jury key\n",
    "    return fallback_key.replace('_', ' ').title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1749654335023,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "R_6Fne1unUMx"
   },
   "outputs": [],
   "source": [
    "def initialize_with_yaml(yaml_file_path: str, total_rounds: int = 3):\n",
    "    \"\"\"Initialize the graph with jury data from YAML file\"\"\"\n",
    "    global graph, jury_backgrounds, current_total_rounds, current_jury_filename\n",
    "\n",
    "    if llm is None:\n",
    "        print(\"Cannot initialize - API key not configured\")\n",
    "        return\n",
    "\n",
    "    graph, jury_backgrounds, current_total_rounds = create_jury_graph(yaml_file=yaml_file_path, total_rounds=total_rounds)\n",
    "    current_total_rounds = total_rounds\n",
    "    current_jury_filename = yaml_file_path  # Track the filename\n",
    "\n",
    "    print(f\"Loaded jury members from {yaml_file_path}:\")\n",
    "    for name in jury_backgrounds.keys():\n",
    "        print(f\"  - {name}\")\n",
    "    print(f\"Set to {total_rounds} deliberation rounds\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0jjONU4k_C4"
   },
   "source": [
    "## Create jury node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749654335031,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "-tv-mNf0SQHK"
   },
   "outputs": [],
   "source": [
    "def create_jury_node(jury_name: str):\n",
    "    \"\"\"Create a jury member node function\"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    def jury_response(state: JuryState):\n",
    "        if llm is None:\n",
    "            message = AIMessage(content=\"Cannot generate response - API key not configured\", name=jury_name)\n",
    "            return {\"messages\": [message]}\n",
    "\n",
    "        background = state[\"jury_backgrounds\"][jury_name]\n",
    "        case = state[\"case_details\"]\n",
    "        current_round = state.get(\"current_round\", 1)\n",
    "        current_juror_index = state.get(\"current_juror_index\", 0)\n",
    "\n",
    "        # Get recent conversation\n",
    "        recent_msgs = state[\"messages\"][-6:] if len(state[\"messages\"]) > 6 else state[\"messages\"]\n",
    "        context = \"\\n\".join([f\"{getattr(msg, 'name', 'User')}: {msg.content}\" for msg in recent_msgs])\n",
    "\n",
    "        prompt = f\"\"\"You are {jury_name}, a jury member in Round {current_round} of deliberation.\n",
    "Background: {background}\n",
    "\n",
    "Case: {case}\n",
    "\n",
    "Recent discussion:\n",
    "{context}\n",
    "\n",
    "As {jury_name}, give your perspective on this case. Consider what others have said and build on the discussion. Keep it to 2-3 sentences and be conversational.\"\"\"\n",
    "\n",
    "        # Add rate limiting and retry logic\n",
    "        max_retries = 3\n",
    "        base_delay = 5  # seconds\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Add a small delay between requests to avoid rate limiting\n",
    "                if attempt > 0:\n",
    "                    delay = base_delay * (2 ** attempt) + random.uniform(0, 2)\n",
    "                    print(f\"‚è≥ Rate limit hit for {jury_name}, waiting {delay:.1f} seconds...\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    # Small delay even on first attempt\n",
    "                    time.sleep(random.uniform(1, 3))\n",
    "                \n",
    "                response = llm.invoke([HumanMessage(content=prompt)])\n",
    "                message = AIMessage(content=response.content, name=jury_name)\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                if \"429\" in error_msg or \"quota\" in error_msg.lower():\n",
    "                    if attempt < max_retries - 1:\n",
    "                        continue  # Retry with longer delay\n",
    "                    else:\n",
    "                        print(f\"‚ùå Rate limit exceeded for {jury_name} after {max_retries} attempts\")\n",
    "                        message = AIMessage(content=f\"I need more time to consider this case due to system limitations.\", name=jury_name)\n",
    "                else:\n",
    "                    print(f\"Error generating response for {jury_name}: {e}\")\n",
    "                    message = AIMessage(content=f\"I need more time to consider this case.\", name=jury_name)\n",
    "                break\n",
    "\n",
    "        # Advance to next juror\n",
    "        next_juror_index = current_juror_index + 1\n",
    "\n",
    "        return {\n",
    "            \"messages\": [message],\n",
    "            \"current_juror_index\": next_juror_index\n",
    "        }\n",
    "\n",
    "    return jury_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqieUwB1AY0_"
   },
   "source": [
    "# Moderator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654335036,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "Vm3myTIbRtq6"
   },
   "outputs": [],
   "source": [
    "def moderator(state: JuryState):\n",
    "    \"\"\"Enhanced moderator to manage multi-round deliberations\"\"\"\n",
    "    current_round = state.get(\"current_round\", 0)\n",
    "    current_juror_index = state.get(\"current_juror_index\", 0)\n",
    "    total_rounds = state.get(\"total_rounds\", 3)\n",
    "\n",
    "    # Only announce the very beginning of deliberation\n",
    "    if current_round == 0 and current_juror_index == 0:\n",
    "        msg = AIMessage(content=\"=== JURY DELIBERATION BEGINS ===\", name=\"Moderator\")\n",
    "        return {\n",
    "            \"messages\": [msg],\n",
    "            \"current_round\": current_round,\n",
    "            \"current_juror_index\": current_juror_index\n",
    "        }\n",
    "\n",
    "    # For all other cases, just pass through without messages\n",
    "    return {\n",
    "        \"current_round\": current_round,\n",
    "        \"current_juror_index\": current_juror_index\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7PUl8IBAdA1"
   },
   "source": [
    "# Final Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1749654335060,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "if2myPnBBGhc"
   },
   "outputs": [],
   "source": [
    "def final_verdict(state: JuryState):\n",
    "    \"\"\"Collect final verdicts from all jury members\"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    if llm is None:\n",
    "        summary = \"=== FINAL VERDICTS ===\\nCannot collect verdicts - API key not configured\"\n",
    "        return {\"messages\": [AIMessage(content=summary, name=\"Final_Verdict\")]}\n",
    "\n",
    "    case = state[\"case_details\"]\n",
    "\n",
    "    # Get all jury members' final decisions\n",
    "    verdicts = {}\n",
    "    for i, jury_name in enumerate(state[\"jury_backgrounds\"].keys()):\n",
    "        background = state[\"jury_backgrounds\"][jury_name]\n",
    "\n",
    "        prompt = f\"\"\"You are {jury_name}, a jury member.\n",
    "Background: {background}\n",
    "\n",
    "Case: {case}\n",
    "\n",
    "After the full deliberation, what is your FINAL VERDICT?\n",
    "Answer only: \"GUILTY\" or \"NOT GUILTY\" and give one sentence explaining why.\n",
    "\n",
    "Format: VERDICT: [GUILTY/NOT GUILTY] - [brief reason]\"\"\"\n",
    "\n",
    "        # Add rate limiting between verdict requests\n",
    "        max_retries = 3\n",
    "        base_delay = 4\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Progressive delay to avoid rate limits\n",
    "                if attempt > 0:\n",
    "                    delay = base_delay * (2 ** attempt) + random.uniform(0, 2)\n",
    "                    print(f\"‚è≥ Rate limit hit collecting verdict from {jury_name}, waiting {delay:.1f} seconds...\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    # Delay between jurors to avoid rapid requests\n",
    "                    if i > 0:  # No delay for first juror\n",
    "                        time.sleep(random.uniform(2, 4))\n",
    "                \n",
    "                response = llm.invoke([HumanMessage(content=prompt)])\n",
    "                verdict_line = response.content.strip()\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                if \"429\" in error_msg or \"quota\" in error_msg.lower():\n",
    "                    if attempt < max_retries - 1:\n",
    "                        continue  # Retry with longer delay\n",
    "                    else:\n",
    "                        print(f\"‚ùå Rate limit exceeded collecting verdict from {jury_name}\")\n",
    "                        verdict_line = f\"VERDICT: NOT GUILTY - Unable to determine due to system limitations\"\n",
    "                else:\n",
    "                    print(f\"Error getting verdict from {jury_name}: {e}\")\n",
    "                    verdict_line = f\"VERDICT: NOT GUILTY - Unable to determine due to technical issue\"\n",
    "                break\n",
    "\n",
    "        verdicts[jury_name] = verdict_line\n",
    "\n",
    "    # Count votes\n",
    "    guilty_votes = sum(1 for v in verdicts.values() if \"GUILTY\" in v.upper() and \"NOT GUILTY\" not in v.upper())\n",
    "    not_guilty_votes = len(verdicts) - guilty_votes\n",
    "\n",
    "    # Final summary\n",
    "    summary = \"=== FINAL VERDICTS ===\\n\"\n",
    "    for jury_name, verdict in verdicts.items():\n",
    "        summary += f\"{jury_name}: {verdict}\\n\"\n",
    "\n",
    "    summary += f\"\\nFINAL TALLY: {guilty_votes} Guilty, {not_guilty_votes} Not Guilty\\n\"\n",
    "\n",
    "    if guilty_votes > not_guilty_votes:\n",
    "        summary += \"JURY DECISION: GUILTY\"\n",
    "    elif not_guilty_votes > guilty_votes:\n",
    "        summary += \"JURY DECISION: NOT GUILTY\"\n",
    "    else:\n",
    "        summary += \"JURY DECISION: HUNG JURY (TIE)\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=summary, name=\"Final_Verdict\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzIrBhp9O4Cy"
   },
   "source": [
    "# Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1749654335065,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "FZfqe1zoROsm"
   },
   "outputs": [],
   "source": [
    "def should_continue(state: JuryState):\n",
    "    \"\"\"Enhanced flow control for multi-round deliberations\"\"\"\n",
    "    current_round = state.get(\"current_round\", 0)\n",
    "    current_juror_index = state.get(\"current_juror_index\", 0)\n",
    "    total_rounds = state.get(\"total_rounds\", 3)\n",
    "    jury_order = state.get(\"jury_order\", [])\n",
    "\n",
    "    # If no jury order set, we're in trouble\n",
    "    if not jury_order:\n",
    "        return \"final_verdict\"\n",
    "\n",
    "    # If we've completed all rounds, go to final verdict\n",
    "    if current_round > total_rounds:\n",
    "        return \"final_verdict\"\n",
    "\n",
    "    # If this is the start (round 0), begin first round\n",
    "    if current_round == 0:\n",
    "        return \"start_round\"\n",
    "\n",
    "    # If we're in a valid round, determine next action\n",
    "    if current_juror_index < len(jury_order):\n",
    "        # Next juror should speak\n",
    "        return jury_order[current_juror_index]\n",
    "    else:\n",
    "        # All jurors have spoken in this round, start next round\n",
    "        return \"start_round\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654335070,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "mNn8ZBPwO5b1"
   },
   "outputs": [],
   "source": [
    "def start_round(state: JuryState):\n",
    "    \"\"\"Start a new round of deliberation\"\"\"\n",
    "    current_round = state.get(\"current_round\", 0) + 1\n",
    "    total_rounds = state.get(\"total_rounds\", 3)\n",
    "    jury_order = state.get(\"jury_order\", [])\n",
    "\n",
    "    # If we've completed all rounds, signal for final verdict\n",
    "    if current_round > total_rounds:\n",
    "        msg = AIMessage(content=\"=== COLLECTING FINAL VERDICTS ===\", name=\"Moderator\")\n",
    "        return {\n",
    "            \"messages\": [msg],\n",
    "            \"current_round\": current_round,\n",
    "            \"current_juror_index\": 0\n",
    "        }\n",
    "\n",
    "    # Announce the new round\n",
    "    msg = AIMessage(content=f\"=== DELIBERATION ROUND {current_round} ===\", name=\"Moderator\")\n",
    "\n",
    "    # Start new round with first juror\n",
    "    return {\n",
    "        \"messages\": [msg],\n",
    "        \"current_round\": current_round,\n",
    "        \"current_juror_index\": 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654335076,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "O8r8guRIPN2f"
   },
   "outputs": [],
   "source": [
    "def set_deliberation_rounds(total_rounds: int):\n",
    "    \"\"\"Set the number of deliberation rounds\"\"\"\n",
    "    global current_total_rounds\n",
    "    current_total_rounds = total_rounds\n",
    "    print(f\"Set deliberation to {total_rounds} rounds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iw3BeXx6oCA"
   },
   "source": [
    "# Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654335081,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "W_53OFhWPxcZ"
   },
   "outputs": [],
   "source": [
    "def create_jury_graph(yaml_file: str = None, background_files: List[str] = None, total_rounds: int = 3):\n",
    "    \"\"\"Create the jury deliberation graph\n",
    "\n",
    "    Args:\n",
    "        yaml_file: Path to YAML file with jury member data\n",
    "        background_files: List of text files (for backward compatibility)\n",
    "        total_rounds: Number of deliberation rounds before final verdict\n",
    "    \"\"\"\n",
    "\n",
    "    # Load backgrounds - prioritize YAML file if provided\n",
    "    if yaml_file:\n",
    "        backgrounds = load_backgrounds_from_yaml(yaml_file)\n",
    "    elif background_files:\n",
    "        backgrounds = load_backgrounds_from_files(background_files)\n",
    "    else:\n",
    "        backgrounds = JURY_MEMBERS.copy()\n",
    "\n",
    "    workflow = StateGraph(JuryState)\n",
    "\n",
    "    # Add moderator, start_round, and final verdict nodes\n",
    "    workflow.add_node(\"moderator\", moderator)\n",
    "    workflow.add_node(\"start_round\", start_round)\n",
    "    workflow.add_node(\"final_verdict\", final_verdict)\n",
    "\n",
    "    # Add jury members\n",
    "    for jury_name in backgrounds.keys():\n",
    "        workflow.add_node(jury_name, create_jury_node(jury_name))\n",
    "\n",
    "    # Set up flow\n",
    "    workflow.add_edge(START, \"moderator\")\n",
    "    workflow.add_conditional_edges(\"moderator\", should_continue)\n",
    "\n",
    "    # start_round determines what happens next\n",
    "    workflow.add_conditional_edges(\"start_round\", should_continue)\n",
    "\n",
    "    # Each jury member goes back to flow control\n",
    "    for jury_name in backgrounds.keys():\n",
    "        workflow.add_conditional_edges(jury_name, should_continue)\n",
    "\n",
    "    # Final verdict goes to END\n",
    "    workflow.add_edge(\"final_verdict\", END)\n",
    "\n",
    "    return workflow.compile(), backgrounds, total_rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Wj2lxtG6sza"
   },
   "source": [
    "# Initialize graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749654335086,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "3z7ksFnw3KA7"
   },
   "outputs": [],
   "source": [
    "# Initialize graph\n",
    "graph, jury_backgrounds, default_rounds = create_jury_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j92-ptG6W55Z"
   },
   "source": [
    "# Stream graph updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1749654335122,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "64p5jpSOPULb"
   },
   "outputs": [],
   "source": [
    "def stream_graph_updates(case_input: str = None, save_to_file: bool = True):\n",
    "    \"\"\"Stream jury deliberation updates and optionally save to markdown file\"\"\"\n",
    "    global deliberation_output, current_case_filename, current_scenario_number\n",
    "\n",
    "    if graph is None:\n",
    "        print(\"Cannot run deliberation - API key not configured\")\n",
    "        return\n",
    "\n",
    "    # Use provided case or current loaded case\n",
    "    if case_input is None:\n",
    "        if current_case is None:\n",
    "            print(\"No case provided and no case loaded from file\")\n",
    "            return\n",
    "        case_input = current_case\n",
    "    else:\n",
    "        # If case is provided directly, reset file tracking\n",
    "        if case_input != current_case:\n",
    "            current_case_filename = None\n",
    "            current_scenario_number = None\n",
    "\n",
    "    # Clear previous output and prepare for new deliberation\n",
    "    deliberation_output = []\n",
    "\n",
    "    # Create jury order from backgrounds\n",
    "    jury_order = list(jury_backgrounds.keys())\n",
    "    juror_colors = assign_juror_colors(jury_order)\n",
    "\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=case_input)],\n",
    "        \"case_details\": case_input,\n",
    "        \"jury_backgrounds\": jury_backgrounds,\n",
    "        \"current_round\": 0,\n",
    "        \"current_juror_index\": 0,\n",
    "        \"total_rounds\": current_total_rounds,\n",
    "        \"jury_order\": jury_order\n",
    "    }\n",
    "\n",
    "    # Process the deliberation\n",
    "    for event in graph.stream(initial_state):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and value[\"messages\"]:\n",
    "                last_message = value[\"messages\"][-1]\n",
    "                speaker = getattr(last_message, 'name', 'System')\n",
    "                content = last_message.content\n",
    "\n",
    "                # Print to console\n",
    "                print(f\"{speaker}: {content}\")\n",
    "                print()\n",
    "\n",
    "                # Format and store for markdown file\n",
    "                if save_to_file:\n",
    "                    formatted_output = format_speaker_output(speaker, content, juror_colors)\n",
    "                    deliberation_output.append(formatted_output)\n",
    "\n",
    "    # Save to markdown file if requested\n",
    "    if save_to_file and deliberation_output:\n",
    "        save_deliberation_to_markdown(case_input, deliberation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-O_95FlAWlf4"
   },
   "source": [
    "# Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1749654335124,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "fscMYQ2AWmsN"
   },
   "outputs": [],
   "source": [
    "# Global variables for output capturing and file tracking\n",
    "current_case = None\n",
    "current_total_rounds = default_rounds\n",
    "deliberation_output = []  # Store all output for saving to file\n",
    "current_jury_filename = None\n",
    "current_case_filename = None\n",
    "current_scenario_number = None\n",
    "\n",
    "# Create temporary download directory (similar to upload directory setup)\n",
    "DOWNLOAD_DIR = tempfile.mkdtemp(prefix=\"jury_downloads_\")\n",
    "print(f\"Download directory: {DOWNLOAD_DIR}\")\n",
    "\n",
    "# Color mapping for different speakers\n",
    "SPEAKER_COLORS = {\n",
    "    \"Moderator\": \"#2E8B57\",      # Sea Green\n",
    "    \"Final_Verdict\": \"#8B0000\",   # Dark Red\n",
    "    # Default juror colors (will be assigned dynamically)\n",
    "    \"default_colors\": [\n",
    "        \"#4169E1\",  # Royal Blue\n",
    "        \"#DC143C\",  # Crimson\n",
    "        \"#FF8C00\",  # Dark Orange\n",
    "        \"#9932CC\",  # Dark Orchid\n",
    "        \"#228B22\",  # Forest Green\n",
    "        \"#FF1493\",  # Deep Pink\n",
    "        \"#8B4513\",  # Saddle Brown\n",
    "        \"#00CED1\",  # Dark Turquoise\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1749654335156,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "kNs8LA2inIJ_"
   },
   "outputs": [],
   "source": [
    "def assign_juror_colors(jury_names):\n",
    "    \"\"\"Assign colors to jury members\"\"\"\n",
    "    colors = {}\n",
    "    available_colors = SPEAKER_COLORS[\"default_colors\"]\n",
    "\n",
    "    for i, name in enumerate(jury_names):\n",
    "        if i < len(available_colors):\n",
    "            colors[name] = available_colors[i]\n",
    "        else:\n",
    "            # If more jurors than colors, cycle through\n",
    "            colors[name] = available_colors[i % len(available_colors)]\n",
    "\n",
    "    return colors\n",
    "\n",
    "def format_speaker_output(speaker, content, juror_colors):\n",
    "    \"\"\"Format speaker output with colors for markdown\"\"\"\n",
    "    if speaker in juror_colors:\n",
    "        color = juror_colors[speaker]\n",
    "    elif speaker in SPEAKER_COLORS:\n",
    "        color = SPEAKER_COLORS[speaker]\n",
    "    else:\n",
    "        color = \"#000000\"  # Default black\n",
    "\n",
    "    return f'<span style=\"color: {color}\"><strong>{speaker}:</strong></span> {content}'\n",
    "\n",
    "def clean_filename_for_output(filepath):\n",
    "    \"\"\"Extract clean filename without extension and path\"\"\"\n",
    "    if filepath is None:\n",
    "        return \"unknown\"\n",
    "\n",
    "    # Get just the filename without path\n",
    "    filename = filepath.split('/')[-1].split('\\\\')[-1]\n",
    "\n",
    "    # Remove extension\n",
    "    filename = filename.rsplit('.', 1)[0]\n",
    "\n",
    "    # Replace spaces and special characters with underscores\n",
    "    filename = filename.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remove any non-alphanumeric characters except underscores\n",
    "    filename = re.sub(r'[^a-zA-Z0-9_]', '', filename)\n",
    "\n",
    "    return filename\n",
    "\n",
    "def save_deliberation_to_markdown(case_details, output_list, filename=None):\n",
    "    \"\"\"Save deliberation output to a markdown file with enhanced naming\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Build filename components\n",
    "        jury_part = clean_filename_for_output(current_jury_filename) if current_jury_filename else \"default_jury\"\n",
    "        case_part = clean_filename_for_output(current_case_filename) if current_case_filename else \"direct_case\"\n",
    "        scenario_part = f\"scenario{current_scenario_number}\" if current_scenario_number else \"full\"\n",
    "\n",
    "        filename = f\"deliberation_{jury_part}_{case_part}_{scenario_part}_{timestamp}.md\"\n",
    "\n",
    "    # Save to download directory instead of current directory\n",
    "    full_filepath = os.path.join(DOWNLOAD_DIR, filename)\n",
    "\n",
    "    # Create markdown content\n",
    "    markdown_content = f\"\"\"# Jury Deliberation Report\n",
    "\n",
    "**Generated on:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "**Configuration:**\n",
    "- Jury File: {current_jury_filename or \"Default jury members\"}\n",
    "- Case File: {current_case_filename or \"Direct input\"}\n",
    "- Scenario: {current_scenario_number if current_scenario_number else \"Full case\"}\n",
    "- Rounds: {current_total_rounds}\n",
    "\n",
    "## Case Details\n",
    "\n",
    "{case_details}\n",
    "\n",
    "---\n",
    "\n",
    "## Deliberation Process\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Add all the captured output\n",
    "    for line in output_list:\n",
    "        markdown_content += line + \"\\n\\n\"\n",
    "\n",
    "    # Add color legend\n",
    "    markdown_content += \"\\n---\\n\\n## Color Legend\\n\\n\"\n",
    "\n",
    "    # Get current juror colors\n",
    "    jury_names = list(jury_backgrounds.keys()) if jury_backgrounds else []\n",
    "    juror_colors = assign_juror_colors(jury_names)\n",
    "\n",
    "    # Add Moderator and Final Verdict to legend\n",
    "    all_colors = {**juror_colors, **SPEAKER_COLORS}\n",
    "\n",
    "    for speaker, color in all_colors.items():\n",
    "        if speaker != \"default_colors\":\n",
    "            markdown_content += f'<span style=\"color: {color}\"><strong>{speaker}</strong></span>\\n\\n'\n",
    "\n",
    "    # Save to file\n",
    "    try:\n",
    "        with open(full_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(markdown_content)\n",
    "        print(f\"üìÑ Deliberation saved to: {full_filepath}\")\n",
    "        return full_filepath\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving deliberation: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_download_directory():\n",
    "    \"\"\"Get the download directory path for external access (e.g., Flask app)\"\"\"\n",
    "    return DOWNLOAD_DIR\n",
    "\n",
    "def list_download_files():\n",
    "    \"\"\"List all files available in the download directory\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(DOWNLOAD_DIR):\n",
    "            files = [f for f in os.listdir(DOWNLOAD_DIR) if f.endswith('.md')]\n",
    "            return [(f, os.path.join(DOWNLOAD_DIR, f)) for f in sorted(files, reverse=True)]\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error listing download files: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwLHmMYn74Cc"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKLqt3QjaQb7"
   },
   "source": [
    "## Main interaction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1749654335164,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "jHuRltOzJVuQ"
   },
   "outputs": [],
   "source": [
    "# Main interaction loop\n",
    "def main(interactive: bool = False, save_to_file: bool = True):\n",
    "    \"\"\"Main function to run jury deliberation\n",
    "\n",
    "    Args:\n",
    "        interactive: If True, runs interactive mode. If False, auto-runs with loaded case.\n",
    "        save_to_file: Whether to save deliberation to markdown file\n",
    "    \"\"\"\n",
    "    print(\"=== JURY DELIBERATION CHATBOT (Powered by Gemini) ===\")\n",
    "\n",
    "    # Check if LLM is properly initialized\n",
    "    if llm is None:\n",
    "        print(\"\\n‚ùå SETUP REQUIRED:\")\n",
    "        print(\"1. Get a free API key from: https://aistudio.google.com/app/apikey\")\n",
    "        print(\"2. Set the environment variable:\")\n",
    "        print(\"   export GOOGLE_API_KEY='your-api-key-here'\")\n",
    "        print(\"   (or set it in your script/notebook)\")\n",
    "        print(\"\\nExiting...\")\n",
    "        return\n",
    "\n",
    "    # If case is pre-loaded and not in interactive mode, run automatically\n",
    "    if not interactive and current_case is not None:\n",
    "        print(\"üöÄ Auto-starting deliberation with pre-loaded case and jury...\")\n",
    "        print(f\"\\nJury Members: {list(jury_backgrounds.keys())}\")\n",
    "        print(f\"Deliberation Rounds: {current_total_rounds}\")\n",
    "        print(f\"\\nCase: {current_case}\\n\")\n",
    "        print(\"üèõÔ∏è Starting deliberation...\\n\")\n",
    "        stream_graph_updates(save_to_file=save_to_file)\n",
    "        print(\"\\nüèÅ Deliberation completed!\")\n",
    "        return\n",
    "\n",
    "    # Interactive mode\n",
    "    if interactive:\n",
    "      print(\"Commands:\")\n",
    "      print(\"‚Ä¢ 'load <yaml_file>' - Load jury members from YAML file\")\n",
    "      print(\"‚Ä¢ 'load <yaml_file> <rounds>' - Load jury members and set rounds\")\n",
    "      print(\"‚Ä¢ 'rounds <number>' - Set number of deliberation rounds\")\n",
    "      print(\"‚Ä¢ 'case <case_file>' - Load case from text file\")\n",
    "      print(\"‚Ä¢ 'case <case_file> <scenario_number>' - Load specific scenario from file\")\n",
    "      print(\"‚Ä¢ 'scenarios <case_file>' - List available scenarios in file\")\n",
    "      print(\"‚Ä¢ 'deliberate' - Start deliberation with loaded case\")\n",
    "      print(\"‚Ä¢ 'deliberate nosave' - Start deliberation without saving to file\")\n",
    "      print(\"‚Ä¢ 'quit', 'exit', or 'q' - Stop\")\n",
    "      print(\"‚Ä¢ Or type case details directly for immediate deliberation\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"Enter command or case details: \")\n",
    "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "\n",
    "            # Check if user wants to load YAML file\n",
    "            if user_input.lower().startswith(\"load \"):\n",
    "                parts = user_input[5:].strip().split()\n",
    "                yaml_file = parts[0]\n",
    "                rounds = int(parts[1]) if len(parts) > 1 else 3\n",
    "\n",
    "                try:\n",
    "                    initialize_with_yaml(yaml_file, rounds)\n",
    "                    print(\"Jury members loaded successfully!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading YAML file: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Check if user wants to set rounds\n",
    "            if user_input.lower().startswith(\"rounds \"):\n",
    "                try:\n",
    "                    rounds = int(user_input[7:].strip())\n",
    "                    set_deliberation_rounds(rounds)\n",
    "                except ValueError:\n",
    "                    print(\"Invalid number of rounds. Please enter a number.\")\n",
    "                continue\n",
    "\n",
    "            # Check if user wants to load case file\n",
    "            if user_input.lower().startswith(\"case \"):\n",
    "                parts = user_input[5:].strip().split()\n",
    "                case_file = parts[0]\n",
    "                scenario_num = int(parts[1]) if len(parts) > 1 else None\n",
    "\n",
    "                try:\n",
    "                    initialize_with_case(case_file, scenario_num)\n",
    "                    print(\"Case loaded successfully!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading case file: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Check if user wants to list scenarios\n",
    "            if user_input.lower().startswith(\"scenarios \"):\n",
    "                case_file = user_input[10:].strip()\n",
    "                scenarios = list_scenarios_in_file(case_file)\n",
    "                if scenarios:\n",
    "                    print(f\"Available scenarios in {case_file}:\")\n",
    "                    for num, title in scenarios:\n",
    "                        print(f\"  {num}: {title}\")\n",
    "                else:\n",
    "                    print(\"No scenarios found or file error\")\n",
    "                continue\n",
    "\n",
    "            # Check if user wants to deliberate with loaded case\n",
    "            if user_input.lower().startswith(\"deliberate\"):\n",
    "                if current_case is None:\n",
    "                    print(\"No case loaded. Use 'case <filename>' to load a case first.\")\n",
    "                    continue\n",
    "\n",
    "                # Check if user wants to save or not\n",
    "                save_file = \"nosave\" not in user_input.lower()\n",
    "\n",
    "                print(f\"\\nüèõÔ∏è Starting deliberation with loaded case...\\n\")\n",
    "                stream_graph_updates(save_to_file=save_file)\n",
    "                print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            # Treat as direct case input for immediate deliberation\n",
    "            if user_input.strip():\n",
    "                print(f\"\\nCase: {user_input}\\n\")\n",
    "                stream_graph_updates(user_input, save_to_file=save_to_file)\n",
    "                print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Trying with fallback example...\")\n",
    "            # Fallback example\n",
    "            user_input = \"John stole a laptop worth $1200 from a coffee shop. He was caught with it 3 days later but claims he bought it from someone on the street for $300. He has no prior record but recently lost his job.\"\n",
    "            print(\"Case: \" + user_input)\n",
    "            stream_graph_updates(user_input, save_to_file=save_to_file)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7OiVx0maSRP"
   },
   "source": [
    "## `run_deliberation` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749654335167,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "7wU3XctXJLsb"
   },
   "outputs": [],
   "source": [
    "def run_deliberation(jury_file: str = None, case_file: str = None, scenario_number: int = None, total_rounds: int = 3, save_to_file: bool = True):\n",
    "    \"\"\"Convenience function to run a complete deliberation session\n",
    "\n",
    "    Args:\n",
    "        jury_file: Path to YAML file with jury members\n",
    "        case_file: Path to text file with case details\n",
    "        scenario_number: If case file has multiple scenarios, specify which one\n",
    "        total_rounds: Number of deliberation rounds before final verdict\n",
    "        save_to_file: Whether to save deliberation to markdown file\n",
    "    \"\"\"\n",
    "    print(\"=== AUTOMATED JURY DELIBERATION ===\")\n",
    "\n",
    "    if llm is None:\n",
    "        print(\"‚ùå API key not configured. Cannot run deliberation.\")\n",
    "        return\n",
    "\n",
    "    # Load jury members if specified\n",
    "    if jury_file:\n",
    "        try:\n",
    "            initialize_with_yaml(jury_file, total_rounds)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading jury file: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        # Set rounds even if no jury file specified\n",
    "        set_deliberation_rounds(total_rounds)\n",
    "\n",
    "    # Load case if specified\n",
    "    if case_file:\n",
    "        try:\n",
    "            initialize_with_case(case_file, scenario_number)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading case file: {e}\")\n",
    "            return\n",
    "\n",
    "    # Run deliberation\n",
    "    if current_case is None:\n",
    "        print(\"‚ùå No case loaded. Cannot start deliberation.\")\n",
    "        return\n",
    "\n",
    "    print(\"üöÄ Starting automated deliberation...\")\n",
    "    print(f\"\\nJury Members: {list(jury_backgrounds.keys())}\")\n",
    "    print(f\"Deliberation Rounds: {current_total_rounds}\")\n",
    "    print(f\"\\nCase Preview: {current_case[:200]}{'...' if len(current_case) > 200 else ''}\\n\")\n",
    "    print(\"üèõÔ∏è Beginning deliberation...\\n\")\n",
    "\n",
    "    stream_graph_updates(save_to_file=save_to_file)\n",
    "    print(\"\\nüèÅ Deliberation completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJNwg9aGaVw_"
   },
   "source": [
    "## Run `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749654335193,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "9h4tcX_u6Nkq"
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     initialize_with_yaml(\"jurors.yaml\", total_rounds=3)\n",
    "#     initialize_with_case(case_file_path=\"Scenario 1.txt\", scenario_number=1)\n",
    "\n",
    "#     # Display graph visualization\n",
    "#     # try:\n",
    "#     #     print(\"Graph structure:\")\n",
    "#     #     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "#     # except Exception as e:\n",
    "#     #     print(f\"Could not display¬†graph:¬†{e}\")\n",
    "\n",
    "#     print(\"\\n\")\n",
    "#     main(interactive=False, save_to_file=True)  # Auto-run with pre-loaded case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MahhJjofgGLP"
   },
   "source": [
    "## Run `run_deliberation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8721,
     "status": "ok",
     "timestamp": 1749654343919,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "bx2KnUlXoOcn",
    "outputId": "89af5b9d-c28c-46d3-c1c9-411303753576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AUTOMATED JURY DELIBERATION ===\n",
      "Loaded jury members from republican_and_democratic.yaml:\n",
      "  - Michelle Chavez\n",
      "  - Rebecca Martin\n",
      "Set to 3 deliberation rounds\n",
      "\n",
      "‚úÖ Loaded Scenario 1 from Scenario 1.txt\n",
      "Case Preview: Scenario 1: \n",
      "Background: Tomer and Stan are accused of murder. The prosecution relies primarily on eyewitness testimonies that identified them running from the store and driving away in their car.\n",
      "Pre...\n",
      "\n",
      "üöÄ Starting automated deliberation...\n",
      "\n",
      "Jury Members: ['Michelle Chavez', 'Rebecca Martin']\n",
      "Deliberation Rounds: 3\n",
      "\n",
      "Case Preview: Scenario 1: \n",
      "Background: Tomer and Stan are accused of murder. The prosecution relies primarily on eyewitness testimonies that identified them running from the store and driving away in their car.\n",
      "Pre...\n",
      "\n",
      "üèõÔ∏è Beginning deliberation...\n",
      "\n",
      "Moderator: === JURY DELIBERATION BEGINS ===\n",
      "\n",
      "Moderator: === DELIBERATION ROUND 1 ===\n",
      "\n",
      "Michelle Chavez: Well, that was quite the cross-examination. It sounds like Mrs. Cohen's testimony might not be as reliable as the prosecution wants us to believe, especially with the new glasses and her trouble reading the headline. I think we need to consider this carefully before we jump to any conclusions.\n",
      "\n",
      "Rebecca Martin: Michelle makes a good point. The defense attorney definitely poked some holes in Mrs. Cohen's testimony. I think we need to weigh how much weight we give to her eyewitness account, especially considering the issues with her vision at the time.\n",
      "\n",
      "Moderator: === DELIBERATION ROUND 2 ===\n",
      "\n",
      "Michelle Chavez: Okay, so Rebecca's right, that lawyer really went after Mrs. Cohen. I'm still not sure what to think, though. Even with the glasses issue, she *thought* she saw something, and maybe she did. We need to hear from other witnesses before I can make up my mind.\n",
      "\n",
      "Rebecca Martin: I agree with Michelle that we shouldn't dismiss Mrs. Cohen's testimony entirely, but the defense raised serious doubts about its accuracy. The fact that she struggled to read the headline so close up, coupled with the new glasses, makes me question how well she could really see the details she described from a distance. We definitely need to hear from other witnesses and see if their accounts corroborate hers before we can rely on her testimony.\n",
      "\n",
      "Moderator: === DELIBERATION ROUND 3 ===\n",
      "\n",
      "Michelle Chavez: Okay, so we all agree Mrs. Cohen's testimony is shaky at best. I'm leaning towards discounting it almost entirely, especially since she couldn't even read the newspaper headline. Let's really focus on the other evidence and witnesses to see if there's anything more solid to go on.\n",
      "\n",
      "Rebecca Martin: I'm with you both. Mrs. Cohen's testimony is definitely compromised. Let's put it on the back burner and see what the other evidence and witnesses bring to the table before we give it any real weight.\n",
      "\n",
      "Moderator: === COLLECTING FINAL VERDICTS ===\n",
      "\n",
      "Final_Verdict: === FINAL VERDICTS ===\n",
      "Michelle Chavez: VERDICT: NOT GUILTY - The witness's credibility is severely damaged due to her vision issues and recent lens replacement, making her identification unreliable.\n",
      "Rebecca Martin: VERDICT: NOT GUILTY - The eyewitness testimony is unreliable due to the witness's vision issues and recent lens replacement, creating reasonable doubt.\n",
      "\n",
      "FINAL TALLY: 0 Guilty, 2 Not Guilty\n",
      "JURY DECISION: NOT GUILTY\n",
      "\n",
      "üìÑ Deliberation saved to: deliberation_republican_and_democratic_Scenario_1_scenario1_20250611_150544.md\n",
      "\n",
      "üèÅ Deliberation completed!\n"
     ]
    }
   ],
   "source": [
    "# Commented out - this was interfering with Flask app calls\n",
    "# run_deliberation(jury_file='republican_and_democratic.yaml',\n",
    "#                      case_file=\"Scenario 1.txt\",\n",
    "#                      scenario_number=1,\n",
    "#                      total_rounds=3,\n",
    "#                      save_to_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdpP5ZRhi_o0"
   },
   "source": [
    "# All test simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1749654343953,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "ONiGOLeujEFi",
    "outputId": "435b476e-3625-428e-ef4e-dab63dff0e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['republican_and_democratic.yaml']\n"
     ]
    }
   ],
   "source": [
    "jurors_files = [file for file in os.listdir() if file.endswith('.yaml')]\n",
    "print(jurors_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749654343964,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "O5_shv--jBt1"
   },
   "outputs": [],
   "source": [
    "# for jurors_yaml_file in jurors_files:\n",
    "#   for scenarion_num in range(1, 4):\n",
    "\n",
    "#     print(f\"=== {jurors_yaml_file} ===\")\n",
    "\n",
    "#     # initialize_with_yaml(jurors_yaml_file, total_rounds=3)\n",
    "#     # initialize_with_case(case_file_path=\"Scenario 1.txt\", scenario_number=scenarion_num)\n",
    "#     # print(\"\\n\")\n",
    "#     # main(interactive=False, save_to_file=True)  # Auto-run with pre-loaded case\n",
    "\n",
    "#     run_deliberation(jury_file=jurors_yaml_file,\n",
    "#                      case_file=\"Scenario 1.txt\",\n",
    "#                      scenario_number=scenarion_num,\n",
    "#                      total_rounds=3,\n",
    "#                      save_to_file=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
